from argparse           import ArgumentParser
from multiprocessing    import Pool
from os                 import listdir, chdir, path, remove
from subprocess         import run

from file_services.paf_file_service   import PafFileService
from file_services.utils              import get_read_reader, get_read_writer

class MyArgumentParser(ArgumentParser):

    prog        =   "MapSampleSequences"

    description =   """
                    ----------
                    Commandline tool that filters query sequences by mapping them to a 
                    refernece 
                    """
    
    def __init__(self) -> None:

        super().__init__(prog=self.prog, description=self.description)

        self.add_argument("query_file")
        self.add_argument("reference_file")
        self.add_argument("-m","--mode",
                          help="Minimap2 mapping mode")
        self.add_argument("-t","--threads",
                          default=2,
                          type=int,
                          help="Number of threads")
        self.add_argument("-s","--score",
                          default=0,
                          type=int,
                          help="Minimum alignemt score")
        
class SequenceMappingQueue():
    """
    A queue for the parallel reading of sequences and their corresponding mappings from
    .paf-files generated by minimap2 in single-threaded mode.

    Idea:
    The Queue holds a single query and a list of n mappings, the first n-1 of them
    corresponding to the query pair.

    Using queue() yields the query and all it's corresponding mappings and removes
    them from the queue. The previous state of the queue is then restored by first loading
    the next query. If it does not correspond to the query, the state of the queue is
    already restored. If not, more mappings are loaded until we find one that does not
    correspond to the query pair.
    """

    def get_query_id(cls, query):

        return query["header"][1:].split(" ")[0]

    def __init__(self, query, paf):

        self.queries = get_read_reader(query).read(query)
        self.paf     = PafFileService().read(paf)

        self.current_query    = None
        self.current_mappings = [next(self.paf)]

        self.restore_state()
                
    def print_current_state(self):

        print("Current query:")
        print(self.get_query_id(self.current_query))
        print("Current mappings:")
        for m in self.current_mappings:
            print("Query: "+m["query_name"]+" Reference: "+m["target_name"])
            print(m)
        print()

    def restore_state(self):
    
        self.current_query = next(self.queries)
        
        query_id = self.get_query_id(self.current_query)

        while query_id in self.current_mappings[len(self.current_mappings)-1]["query_name"]:
            self.current_mappings.append(next(self.paf))

    def queue(self):
        
        while True:

            yield self.current_query, self.current_mappings[:-1]

            try:  
                self.current_query      = None
                self.current_mappings   = [self.current_mappings[-1]]
                self.restore_state()
            except:
                break
        
def mm2_map(arg):
    if arg[0] == None:
        run(["minimap2",
            "-t", str(1),
            "-o", arg[2]+".paf",
            arg[1],
            arg[2]],
            check=True)
    else:
        run(["minimap2",
            "-x", arg[0],
            "-t", str(1),
            "-o", arg[2]+".paf",
            arg[1],
            arg[2]],
            check=True)
    
def filter_reads(arg):

    print(f"Thread {arg[2]} processing {arg[0]}, {arg[1]}")

    filtered = []
    process  = 0
    filter   = 0

    for sequence, mappings in SequenceMappingQueue(arg[0], arg[1]).queue():
        process += 1
        if any([m for m in mappings if int(m["alignment_quality"])>=arg[3]]):
            filtered.append(sequence)
            filter += 1
        if process % 1_000_000 == 0:
            r = round(100*filter/process,5)
            p = int(process / 1_000_000)
            print("Thread {0}: {1:>3}m processed ({2} % filtered)".format(arg[2], p, r))
    print(f"Thread {arg[2]} done filtering")
    get_read_writer(filtered[0]).write("mss_filtered"+arg[0], filtered, mode="w")      

def main():

    args = MyArgumentParser().parse_args()

    if not path.dirname(args.query_file)=="":
        chdir(path.dirname(args.query_file))

    print("File splitting ...")
    run(["seqtk","split",
         "-n", str(args.threads),
         args.query_file+"split",
         #args.query_file+"split",
         args.query_file
         ],
         check=True)
    
    print("Indexing reference ...")
    if args.mode == None:
        run(["minimap2",
            "-t", str(args.threads),
            "-d", args.reference_file+".mm2idx",
            args.reference_file], check=True)
    else:
        run(["minimap2",
            "-x",args.mode,
            "-t", str(args.threads),
            "-d", args.reference_file+".mm2idx",
            args.reference_file], check=True))
    
    print("Mapping ...")
    query_files = sorted([f for f in listdir() if args.query_file+"split" in f])
    mm2_args = zip([args.mode                       for _ in query_files],
                   [args.reference_file+".mm2idx"   for _ in query_files],
                   query_files)
    with Pool(processes=args.threads) as pool:
        pool.map(mm2_map, mm2_args)

    print("Filtering query sequences ...")
    mapping_files = sorted([f for f in listdir() if f.startswith(args.query_file+"split") and f.endswith(".paf")])
    with Pool(processes=args.threads) as pool:
        pool.map(filter_reads, zip(query_files,
                                   mapping_files,
                                   list(range(args.threads)),
                                   [args.score for _ in query_files]))
        
    print("File merging ...")
    merge_files = sorted(["mss_filtered"+f for f in query_files])
    final_file  = "mss_filtered"+args.query_file
    run(f"cat {' '.join(merge_files)} > {final_file}", shell=True)

    print("Cleanup ...")
    for f in query_files + mapping_files + merge_files:
        remove(f)

    print("----- ------- -----")
    print("----- D O N E -----")
    print("----- ------- -----")

if __name__ == '__main__':
    main()
